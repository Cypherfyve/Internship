{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8913eade",
   "metadata": {},
   "source": [
    "**Q1. Write a Pandas program to create a dictionary based dataset with city and number of person, and then count city wise number of people from a given of data set.**\n",
    "<img src='Q1.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d21776",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_34164/1793555306.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\saivi\\AppData\\Local\\Temp/ipykernel_34164/1793555306.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print(df1)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Miachel']\n",
    "({'city': ['California', 'Los Angeles', 'California', 'California', 'California', 'Los Angelos']\n",
    "print(df1)\n",
    "g1 = df1.groupby([\"city\"]).size().reset_index(name='Number of people')\n",
    "#g1 = df1.groupby([\"city\"]).count()\n",
    "print(g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bec12e",
   "metadata": {},
   "source": [
    "**Q2. Write a Pandas program to group by the first column and get second column as lists in rows.<br>**\n",
    "{'col1':['C1','C1','C2','C2','C2','C3','C2'], 'col2':[1,2,3,3,4,6,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f5beb84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34164/1534092926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'C1,C1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'col2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original DataFrame\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'col2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'col1':['C1,C1','C2','C2','C3','C2'],'col2':[1,2,3,4,5,6]})\n",
    "print(\"Original DataFrame\")\n",
    "print(df)\n",
    "df=df.groupby('col1')['col2'].apply(list)\n",
    "print(\"\\nGroup on col1:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4de23b",
   "metadata": {},
   "source": [
    "**Q3. Write a Pandas program to create a dataframe with following information<br>\n",
    "{'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],<br>\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],<br>\n",
    "        'attempts': [1, 3, 2, 3, np.nan, 3, 1, 1, 2, 1],<br>\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}<br>\n",
    "<br>\n",
    "(i) Identify the column(s) of a given DataFrame which have at least one missing value. [use isna()/isnull()]<br>\n",
    "(ii) Count the NaN values in each column and then count in totals in DataFrame.<br>\n",
    "(iii) Drop those rows from a given DataFrame in which spicific columns have missing values, say <u>attempts</u>.<br>\n",
    "(iv) Replace all the NaN values with Zero's in a column of a dataframe.<br>\n",
    "(v) Drop a list of rows (2 and 3) from a specified DataFrame and then reset index.<br>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea282fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_34164/1080781301.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\saivi\\AppData\\Local\\Temp/ipykernel_34164/1080781301.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael',\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, np.nan, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']\n",
    "df = pd.DataFrame(exam_data)\n",
    "print(\"Original DataFrame\")\n",
    "print(df)\n",
    "#(i)\n",
    "print('================================================')\n",
    "print(\"\\nIdentify the columns which have at least one missing value:\")\n",
    "print(df.isna().any())\n",
    "#(ii)\n",
    "print('================================================')\n",
    "print(\"\\nNumber of NaN values in each columns and total:\")\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().values.sum())\n",
    "#(iii)\n",
    "print('================================================')\n",
    "print(\"\\nDrop those rows in which specific columns have missing values:\")\n",
    "result = df.dropna(subset=['attempts'])\n",
    "print(result)\n",
    "#(iv)\n",
    "print('================================================')\n",
    "df = df.fillna(0)\n",
    "print(\"\\nNew DataFrame replacing all NaN with 0:\")\n",
    "print(df)\n",
    "#(v)\n",
    "print('================================================')\n",
    "print(\"New DataFrame after removing 2nd & 4th rows:\")\n",
    "df = df.drop(df.index[[2,4]])\n",
    "print(df)\n",
    "print(\"\\nReset the Index:\")\n",
    "df=df.reset_index()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b266a",
   "metadata": {},
   "source": [
    "**Q4. Write a Pandas program to create a information dataset as shown below.<br>\n",
    "(i) Split (with faction 0.6) the given DataFrame/Dataset into two random subsets and check the shape of each subset. [use <u>sample(frac)</u>]<br>\n",
    "(ii) Join the two splited dataframes along columns and assign all data.<br>**\n",
    "<img src='Q4.jpg' width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facd909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfb439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949c55ce",
   "metadata": {},
   "source": [
    "**Q5. Write a Pandas program create two seperate student datasets with information like student_id, name, and mark.**\n",
    "<img src='Q5a.jpg' width=\"300\" height=\"300\">\n",
    "<img src='Q5b.jpg' width=\"300\" height=\"300\">\n",
    "**(i) Join the two dataframes using the common column 'student_id' of both dataframes.<br>\n",
    "(ii)  Join the two dataframes with matching records from both sides where available.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b86c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', '\n",
    "'marks': [200, 210, 190, 222, 199]})\n",
    "student_data2 = pd.DataFrame({\n",
    "'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser Will\n",
    "'marks': [201, 200, 198, 219, 201]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a284d7",
   "metadata": {},
   "source": [
    "**Q6. Write a Pandas program to split a given dataframe into groups and create a new column with count from GroupBy.**\n",
    "<img src='Q6.jpg' width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', None)\n",
    "df = pd.DataFrame({\n",
    "'book_name':['Book1','Book2','Book3','Book4','Book1','Book2','Book3','Book5'],\n",
    "'book_type':['Math','Physics','Computer','Science','Math','Physics','Computer','Engl\n",
    "'book_id':[1,2,3,4,1,2,3,5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180896d4",
   "metadata": {},
   "source": [
    "**Q7. Write a Pandas program to split a given dataframe into groups with multiple aggregations.\n",
    "Split the following given dataframe by school code, class and get mean, max value of height and get sum, min, count value of weight of the school.**\n",
    "<img src='Q7.jpg' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c66e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'school_code': ['s001','s002','s003','s001','s002','s001'],\n",
    "'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mc\n",
    "'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/20\n",
    "'age': [12, 12, 13, 13, 14, 12],\n",
    "'height': [173, 192, 186, 167, 151, 159],\n",
    "'weight': [35, 32, 33, 30, 31, 32],\n",
    "'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nGroup by with multiple aggregations:\")\n",
    "result = df.groupby(['school_code','class']).agg({'height': ['max', 'mean'],\n",
    "'weight': ['sum','min','count']})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009bde1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267072d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
